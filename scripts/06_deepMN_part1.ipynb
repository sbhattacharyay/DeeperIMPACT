{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train DeepMN models across model configurations\n",
    "\n",
    "Shubhayu Bhattacharyay\n",
    "<br>\n",
    "Ari Ercole"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fundamental methods\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import glob\n",
    "import random\n",
    "import warnings\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as cp\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "warnings.filterwarnings(action=\"ignore\")\n",
    "\n",
    "# Tensorflow, and CORAL methods (neural network methods)\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "import tensorflow.python.keras.backend as K\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.layers import Input, Activation, Dense, Dropout, Conv2D, Flatten, LSTM, Permute, Reshape, AlphaDropout, BatchNormalization\n",
    "import coral_ordinal as coral\n",
    "\n",
    "# Keras Tuner methods\n",
    "import kerastuner as kt\n",
    "from kerastuner.tuners import RandomSearch, Hyperband\n",
    "\n",
    "# SciKit-Learn methods\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.preprocessing import LabelBinarizer, PowerTransformer, label_binarize\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score, f1_score\n",
    "\n",
    "# Import hiplot to visualize tuning results\n",
    "import hiplot as hip\n",
    "\n",
    "# Load custom functions\n",
    "%run -i 'functions/ordinal_encoding.py'\n",
    "%run -i 'functions/multiclass_metrics.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Establishing learning environment for DeepMN models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define function to build and compile DeepMN functions of different hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_deepMN(no_layers,units_vector):\n",
    "    deepMN = Sequential()\n",
    "    deepMN.add(Input(shape=(10,)))\n",
    "    # Adding variable amount of hidden layers\n",
    "    for i in range(no_layers):\n",
    "        deepMN.add(Dense(\n",
    "            units=units_vector[i],\n",
    "            activation='relu'))\n",
    "        deepMN.add(Dropout(0.2))\n",
    "    # Adding final output layer     \n",
    "    deepMN.add(Dense(7, activation='softmax'))\n",
    "    # Compiling neural network model\n",
    "    deepMN.compile(\n",
    "        optimizer=tf.keras.optimizers.RMSprop(), \n",
    "        loss='categorical_crossentropy', \n",
    "        metrics=[tf.keras.metrics.CategoricalAccuracy(),f1_score_m])\n",
    "    # Return neural network function\n",
    "    return deepMN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define tuning grid for model configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_options = range(2,5)\n",
    "units_options = [128,256,512]\n",
    "smote_options = [0,1]\n",
    "\n",
    "layer_smote_combos = np.array(np.meshgrid(layer_options, smote_options)).reshape(2, len(layer_options)*len(smote_options)).T\n",
    "\n",
    "tuning_grid = pd.DataFrame(np.empty((0,3)))\n",
    "for i in range(np.shape(layer_smote_combos)[0]):\n",
    "    curr_tuning_options = pd.DataFrame({\"layers\":layer_smote_combos[i,0],\\\n",
    "                                        \"smote\": layer_smote_combos[i,1],\\\n",
    "                                        \"units\": list(itertools.product(units_options,repeat = layer_smote_combos[i,0]))})\n",
    "    tuning_grid.columns = curr_tuning_options.columns\n",
    "    tuning_grid = tuning_grid.append(curr_tuning_options,ignore_index=True)\n",
    "tuning_grid[\"tune_idx\"] = np.arange(tuning_grid.shape[0]) + 1\n",
    "tuning_grid.to_csv('../repeated_cv/dl_tuning_grid.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Train DeepMN with Bootstrap Bias Corrected with Dropping Cross-Validation (BBCD-CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish dataframe of all tuning index-GOSE-class combinations for AUC\n",
    "viable_indices = pd.DataFrame(list(itertools.product(tuning_grid.tune_idx.astype('int').unique(), ['1','3','4','5','6','7','8','macro-averaged'])),\\\n",
    "                              columns=['tune_idx','class'])\n",
    "\n",
    "# Initialize empty dataframe to store indices that reject null hypothesis (and are thus banned from future interations)\n",
    "banned_tuning_indices = pd.DataFrame(np.empty((0,3)),columns = ['class','aurocs','tune_idx'])\n",
    "\n",
    "# Load testing folds\n",
    "testing_folds = pd.read_csv('../testing_folds.csv')\n",
    "\n",
    "# Initalize empty dataframe to store compiled prediction results\n",
    "deepMN_results_compiled = pd.DataFrame(np.empty((0,16)))\n",
    "\n",
    "# Inititalize dynamic display messages for status updates\n",
    "dh = display('',display_id=True)\n",
    "bs_message = display('',display_id=True)\n",
    "bs_intermediate_status =  display('',display_id=True)\n",
    "banned_message = display('',display_id=True)\n",
    "\n",
    "# Iterate through repeat and fold directories\n",
    "for curr_repeat in testing_folds['repeat.no'].unique():\n",
    "    for curr_fold in testing_folds['fold.no'].unique():\n",
    "        \n",
    "        # Load normalized training set and encode for deepMN\n",
    "        curr_norm_training_set = pd.read_csv(os.path.join('../repeated_cv','Repeat' + str(curr_repeat).zfill(2),'Fold' + str(curr_fold).zfill(1),'norm_train_dataframe.csv'))\n",
    "        curr_norm_training_labels = label_binarize(curr_norm_training_set.GOSE.values,classes=[1,3,4,5,6,7,8])\n",
    "        curr_norm_training_matrix = curr_norm_training_set.drop(columns=['entity_id','PatientType', 'GCS','GOSE']).values\n",
    "        curr_norm_training_class_weights = dict(enumerate(compute_class_weight(\"balanced\", np.sort(curr_norm_training_set.GOSE.unique()), curr_norm_training_set.GOSE.values)))\n",
    "   \n",
    "        # Load SMOTEd normalized training set and encode for deepMN\n",
    "        curr_smote_norm_training_set = pd.read_csv(os.path.join('../repeated_cv','Repeat' + str(curr_repeat).zfill(2),'Fold' + str(curr_fold).zfill(1),'smote_norm_train_dataframe.csv'))\n",
    "        curr_smote_norm_training_labels = label_binarize(curr_smote_norm_training_set.GOSE.values,classes=[1,3,4,5,6,7,8])\n",
    "        curr_smote_norm_training_matrix = curr_smote_norm_training_set.drop(columns=['GOSE']).values\n",
    "        curr_smote_norm_training_class_weights = dict(enumerate(compute_class_weight(\"balanced\", np.sort(curr_smote_norm_training_set.GOSE.unique()), curr_smote_norm_training_set.GOSE.values)))\n",
    "\n",
    "        # Load normalized testing set and encode for deepMN\n",
    "        curr_norm_testing_set = pd.read_csv(os.path.join('../repeated_cv','Repeat' + str(curr_repeat).zfill(2),'Fold' + str(curr_fold).zfill(1),'norm_test_dataframe.csv'))\n",
    "        curr_norm_testing_labels = label_binarize(curr_norm_testing_set.GOSE.values,classes=[1,3,4,5,6,7,8])\n",
    "        curr_norm_testing_matrix = curr_norm_testing_set.drop(columns=['entity_id','PatientType', 'GCS','GOSE']).values\n",
    "        \n",
    "        # Make sub-directory for saving deepMN models in current fold and repeat combination\n",
    "        os.makedirs(os.path.join('../repeated_cv','Repeat' + str(curr_repeat).zfill(2),'Fold' + str(curr_fold).zfill(1),'trained_models','deepMN'),exist_ok=True)\n",
    "        \n",
    "        # Loop through different viable tuning configurations (tune_idx) and train models\n",
    "        for curr_tune_idx in (viable_indices.tune_idx.unique()):\n",
    "            \n",
    "            # Update dynamic message on current tuning status\n",
    "            dh.update('tuning iteration ' + str(curr_tune_idx) + ' out of ' + \\\n",
    "                  str(len(viable_indices.tune_idx.unique())) + ' started for repeat: ' + str(curr_repeat)\\\n",
    "                  + ' and fold: ' + str(curr_fold))\n",
    "            \n",
    "            # Identify current model parameters based on tuning grid\n",
    "            curr_layers = int(tuning_grid.layers[tuning_grid.tune_idx.astype('int') == curr_tune_idx].values)\n",
    "            curr_units = tuning_grid.units[tuning_grid.tune_idx.astype('int') == curr_tune_idx].values[0]\n",
    "            curr_smote = int(tuning_grid.smote[tuning_grid.tune_idx.astype('int') == curr_tune_idx].values[0])\n",
    "            \n",
    "            # Build and compile current model based on tuning grid parameters\n",
    "            curr_mdl = build_deepMN(curr_layers,curr_units)\n",
    "            \n",
    "            # Select training data based on SMOTE indicator\n",
    "            if curr_smote == 1:\n",
    "                curr_mdl.fit(x=curr_smote_norm_training_matrix,\\\n",
    "                             y=curr_smote_norm_training_labels,\\\n",
    "                             batch_size=128,\\\n",
    "                             epochs=7,\\\n",
    "                             verbose = 0,\\\n",
    "                             validation_data = (curr_norm_testing_matrix,curr_norm_testing_labels),\\\n",
    "                             class_weight=curr_smote_norm_training_class_weights)        \n",
    "            else:\n",
    "                curr_mdl.fit(x=curr_norm_training_matrix,\\\n",
    "                             y=curr_norm_training_labels,\\\n",
    "                             batch_size=128,\\\n",
    "                             epochs=7,\\\n",
    "                             verbose = 0,\\\n",
    "                             validation_data = (curr_norm_testing_matrix,curr_norm_testing_labels),\\\n",
    "                             class_weight=curr_norm_training_class_weights)\n",
    "            \n",
    "            # Save current model in appropriate sub-directory\n",
    "            curr_mdl.save(os.path.join('../repeated_cv','Repeat' + str(curr_repeat).zfill(2),\\\n",
    "                                       'Fold' + str(curr_fold).zfill(1),'trained_models','deepMN','deepMN_tuning_' + str(curr_tune_idx).zfill(3) + '.h5'))\n",
    "            \n",
    "            # Compile predictions from current tuning configuration and append to compiled prediction dataframe\n",
    "            curr_mdl_test_pred_probs = pd.DataFrame(curr_mdl.predict(curr_norm_testing_matrix),columns=['prob_GOSE_1', 'prob_GOSE_2_3', 'prob_GOSE_4', 'prob_GOSE_5', 'prob_GOSE_6','prob_GOSE_7','prob_GOSE_8'])\n",
    "            curr_mdl_test_pred_labels = pd.DataFrame(np.transpose(np.vstack((curr_norm_testing_set.GOSE.values,[[1,3,4,5,6,7,8][j] for j in curr_mdl.predict(curr_norm_testing_matrix).argmax(axis=-1)]))),columns=['true_labels','pred_labels'])\n",
    "            curr_mdl_test_final = pd.concat([curr_mdl_test_pred_labels,curr_mdl_test_pred_probs],axis=1)\n",
    "            curr_mdl_test_final[\"repeat.name\"] = curr_repeat\n",
    "            curr_mdl_test_final[\"fold.name\"] = curr_fold\n",
    "            curr_mdl_test_final[\"layers\"] = int(curr_layers)\n",
    "            curr_mdl_test_final[\"SMOTE\"] = int(curr_smote)\n",
    "            curr_mdl_test_final[\"units\"] = [curr_units for j in range(curr_mdl_test_final.shape[0])]\n",
    "            curr_mdl_test_final[\"tune_idx\"] = int(curr_tune_idx)\n",
    "            curr_mdl_test_final[\"entity_id\"] = curr_norm_testing_set.entity_id\n",
    "            deepMN_results_compiled.columns = curr_mdl_test_final.columns\n",
    "            deepMN_results_compiled = deepMN_results_compiled.append(curr_mdl_test_final,ignore_index=True)\n",
    "            \n",
    "        ## BOOSTRAP-DROPPING:\n",
    "        # Update bootstrap status message if more than one viable configuration remains\n",
    "        if len(viable_indices.tune_idx.unique()) == 1:\n",
    "            bs_message.update('only one viable configuration remaining. Bootstrapping skipped for repeat: ' + str(curr_repeat) + ' and fold: ' + str(curr_fold))\n",
    "            continue\n",
    "        else:\n",
    "            bs_message.update('Bootstrapping started for repeat: ' + str(curr_repeat) + ' and fold: ' + str(curr_fold))\n",
    "        \n",
    "        # First, identify optimal configuration based on all available results (after each fold) for each GOSE class and macro-average\n",
    "        aurocs_df = pd.DataFrame(np.empty((0,3)), columns = ['class','aurocs','tune_idx'])\n",
    "        prob_cols = [col for col in deepMN_results_compiled if col.startswith('prob_GOSE_')]\n",
    "        \n",
    "        for curr_tune_idx in (viable_indices.tune_idx.unique()):\n",
    "            # Filter out results with current tune index:\n",
    "            curr_results_idx = list(itertools.compress(range(len(deepMN_results_compiled.tune_idx.astype('int') == int(curr_tune_idx))), deepMN_results_compiled.tune_idx.astype('int') == int(curr_tune_idx)))\n",
    "            filt_results = deepMN_results_compiled.iloc[curr_results_idx,]\n",
    "            curr_labels = label_binarize(filt_results.true_labels.astype('int').values,classes=[1,3,4,5,6,7,8])\n",
    "            \n",
    "            curr_aurocs = roc_auc_score(y_true = curr_labels, y_score = filt_results[prob_cols].values,average=None,multi_class='ovr')\n",
    "            curr_aurocs_df = pd.DataFrame({'class':['1','3','4','5','6','7','8','macro-averaged'],\\\n",
    "                                           'aurocs':np.append(curr_aurocs,np.mean(curr_aurocs)),\\\n",
    "                                          'tune_idx':int(curr_tune_idx)})\n",
    "            \n",
    "            # Filter out classes that are still viable\n",
    "            curr_still_viable_classes = viable_indices['class'][viable_indices.tune_idx == curr_tune_idx]\n",
    "            curr_aurocs_df = curr_aurocs_df[curr_aurocs_df['class'].isin(curr_still_viable_classes)]\n",
    "            \n",
    "            # Append viable AUROC candidates to current pool\n",
    "            aurocs_df = aurocs_df.append(curr_aurocs_df,ignore_index = True)\n",
    "        \n",
    "        # Identify optimal tuning index for each class and sort by class\n",
    "        opt_aurocs_idx = aurocs_df.groupby(['class'])['aurocs'].transform(max) == aurocs_df['aurocs']\n",
    "        opt_aurocs_df = aurocs_df[opt_aurocs_idx].sort_values(by=['class'])\n",
    "        \n",
    "        # Remove optimal rows from the pooled AUROC dataframe to determine which models will be tested for drouput\n",
    "        other_aurocs_df = aurocs_df[~opt_aurocs_idx].sort_values(by=['class'])\n",
    "        \n",
    "        # Randomly draw sample-size-number of patients with replacement 200 times for boostrapping\n",
    "        bootstrap_ids = np.random.choice(deepMN_results_compiled.entity_id.unique(),size = (len(deepMN_results_compiled.entity_id.unique()),200), replace = True)\n",
    "        \n",
    "        # Initialize indicator matrix to determine configurations to eliminate\n",
    "        other_less_thans = np.empty([other_aurocs_df.shape[0],bootstrap_ids.shape[1]],dtype=int)\n",
    "        \n",
    "        # Loop through bootstrap indices\n",
    "        for bs_idx in range(bootstrap_ids.shape[1]):\n",
    "            # Signify current boostrapping index\n",
    "            curr_bootstrap_ids = bootstrap_ids[:,bs_idx]\n",
    "            \n",
    "            # Filter out predictions of current bootstrap patients and tuning indices in the optimal dataframe\n",
    "            opt_results_idx = (deepMN_results_compiled.entity_id.isin(curr_bootstrap_ids)) & (deepMN_results_compiled.tune_idx.astype('int').isin(opt_aurocs_df.tune_idx.astype('int').unique()))\n",
    "            filt_results = deepMN_results_compiled[opt_results_idx]\n",
    "            \n",
    "            # Initialize empty dataframe to store 'best'-configuration AUROCs in the given boostrap sample\n",
    "            curr_bs_opt_aurocs = pd.DataFrame(np.empty((0,3)), columns = ['class','aurocs','tune_idx'])\n",
    "            \n",
    "            for curr_opt_idx in opt_aurocs_df.tune_idx.astype('int').unique():\n",
    "                \n",
    "                #Filter out predictions and labels for current tuning configuration\n",
    "                curr_opt_results_idx = (filt_results.tune_idx.astype('int') == curr_opt_idx)\n",
    "                curr_opt_filt_results = filt_results[curr_opt_results_idx]\n",
    "                curr_opt_labels = label_binarize(curr_opt_filt_results.true_labels.astype('int').values,classes=[1,3,4,5,6,7,8])\n",
    "                \n",
    "                # Calculate AUROCs for current optimal AUROC candidate and add approprate classes to current bootstrap optimals dataframe\n",
    "                curr_opt_auroc = roc_auc_score(y_true = curr_opt_labels, y_score = curr_opt_filt_results[prob_cols].values,average=None,multi_class='ovr')\n",
    "                curr_opt_aurocs_df = pd.DataFrame({'class':['1','3','4','5','6','7','8','macro-averaged'],\\\n",
    "                               'aurocs':np.append(curr_opt_auroc,np.mean(curr_opt_auroc)),\\\n",
    "                              'tune_idx':int(curr_opt_idx)})\n",
    "                curr_opt_classes = opt_aurocs_df['class'][opt_aurocs_df.tune_idx == curr_opt_idx]\n",
    "                curr_bs_opt_aurocs = curr_bs_opt_aurocs.append(curr_opt_aurocs_df[curr_opt_aurocs_df['class'].isin(curr_opt_classes)],ignore_index = True)\n",
    "                \n",
    "            # Sort current bootstrap optimals dataframe by GOSE class\n",
    "            curr_bs_opt_aurocs = curr_bs_opt_aurocs.sort_values(by=['class'])\n",
    "            \n",
    "            # Iterate through other tuning indices and determine whether current bootstrap AUC is lower\n",
    "            for curr_other_idx in other_aurocs_df.tune_idx.astype('int').unique():\n",
    "                \n",
    "                #Filter out predictions and labels for current suboptimal tuning configuration\n",
    "                curr_other_results_idx = (deepMN_results_compiled.entity_id.isin(curr_bootstrap_ids))&(deepMN_results_compiled.tune_idx.astype('int') == curr_other_idx)\n",
    "                curr_other_filt_results = deepMN_results_compiled[curr_other_results_idx]\n",
    "                \n",
    "                # Calculate AUROCs for current suboptimal AUROC candidate and filter out only viable classes and sort by class\n",
    "                curr_other_labels = label_binarize(curr_other_filt_results.true_labels.astype('int').values,classes=[1,3,4,5,6,7,8])         \n",
    "                curr_other_auroc = roc_auc_score(y_true = curr_other_labels, y_score = curr_other_filt_results[prob_cols].values,average=None,multi_class='ovr')\n",
    "                curr_other_aurocs_df = pd.DataFrame({'class':['1','3','4','5','6','7','8','macro-averaged'],\\\n",
    "                                                   'aurocs':np.append(curr_other_auroc,np.mean(curr_other_auroc)),\\\n",
    "                                                   'tune_idx':int(curr_other_idx)})\n",
    "                curr_other_classes = other_aurocs_df['class'][other_aurocs_df.tune_idx == curr_other_idx]\n",
    "                curr_other_aurocs_df = curr_other_aurocs_df[curr_other_aurocs_df['class'].isin(curr_other_classes)].sort_values(by=['class'])\n",
    "\n",
    "                # Identify indices of `other_aurocs_df` that match current 'curr_other_aurocs_df' rows\n",
    "                indicator_idx = (other_aurocs_df.tune_idx.astype('int') == curr_other_idx) & (other_aurocs_df['class'].isin(curr_other_classes))\n",
    "                \n",
    "                # Compare current suboptimal AUCs to the optimal AUCs under current option\n",
    "                other_less_thans[indicator_idx,bs_idx] = (curr_other_aurocs_df.aurocs.reset_index(drop=True) < curr_bs_opt_aurocs.aurocs[curr_bs_opt_aurocs['class'].isin(curr_other_classes)].reset_index(drop=True)).astype('int').values\n",
    "            \n",
    "            bs_intermediate_status.update('Bootstrap no. ' + str(bs_idx+1) + ' out of ' + str(bootstrap_ids.shape[1]) + ' completed.')\n",
    "            \n",
    "        # Add tuning indices that fail the hypothesis test for given GOSE classes to the running list of banned tuning indices\n",
    "        banned_tuning_indices = banned_tuning_indices.append(other_aurocs_df[np.sum(other_less_thans,1)/bootstrap_ids.shape[1] >= .99],ignore_index = True)\n",
    "        banned_tuning_class_combos = banned_tuning_indices[['tune_idx','class']]\n",
    "        banned_tuning_class_combos.tune_idx = banned_tuning_class_combos.tune_idx.astype('int')\n",
    "        \n",
    "        # Update viable indices by removing banned tuning indices per class\n",
    "        viable_indices = pd.concat([viable_indices, banned_tuning_class_combos, banned_tuning_class_combos]).drop_duplicates(keep=False)\n",
    "        \n",
    "        banned_message.update('Current number of banned indices: '+ str(banned_tuning_indices.shape[0])+' out of '+str(tuning_grid.shape[0]*8) +' possible config-class combinations \\\n",
    "        after repeat: ' + str(curr_repeat) + ' and fold: ' + str(curr_fold))\n",
    "        \n",
    "deepMN_results_compiled.to_csv('../repeated_cv/compiled_predictions/deepMN.csv',index=False)\n",
    "banned_tuning_indices.to_csv('../repeated_cv/deepMN_banned_tuning_indices.csv',index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sb_venv",
   "language": "python",
   "name": "sb_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
